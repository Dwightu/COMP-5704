<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Prof. Frank Dehne</title>


  

  
  
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"></head><body style="color: rgb(0, 0, 0); background-color: rgb(255, 255, 255);" alink="#000000" link="#000000" vlink="#000000">
<table border="0" width="100%">

  <tbody>
    <tr>
      <td height="27" width="45%">
      <h2>COMP 5704: Parallel Algorithms and Applications in Data Science<br>
</h2>
      </td>
      <td height="27" width="10%">
      <p><br>
      </p>
      </td>
      <td height="27" width="45%">
      <p><b>School of Computer Science</b><br>
      <b>Carleton University, Ottawa, Canada</b></p>
      </td>
    </tr>
  </tbody>
</table>

<hr noshade="noshade">
<h2><font color="#005128">Project Title: </font><font><font color="#005128">Explore how the OpenMP can improve application performance</font></font></h2>

<h2><font><font color="#005128">Name: Dehui Yu</font></font></h2>

<h2><font><font color="#005128">E-Mail: dyu105@uottawa.ca</font></font></h2>



<hr noshade="noshade">
<b><font color="#005128">Project Outline:</font></b> 
OpenMP provides a high-level abstract description of parallel algorithms. Programmers specify their intentions by adding specialized pragmas to their source code, so that the compiler can automatically parallelize programs and add synchronous mutex and communication where necessary. However, as a high-level abstraction, OpenMP is not suitable for situations that require complex inter-thread synchronization and mutual exclusion. Another disadvantage of OpenMP is that it cannot be used on non-shared memory systems, such as computer clusters, where MPI is heavily used.
<br>
<br>
CPUs are now generally 4 or more cores, which is good news for computationally intensive programs. In the absence of GPU acceleration, consider using CPU multithreading for acceleration. This has great value in areas such as image processing. OpenMP is such a concurrent programming framework. It supports C language, C++ and Fortran, and compilers that support OpenMP include Sun Studio, Intel Compiler, Microsoft Visual Studio, and GCC.
<br>
<br>
Our project is to explore how much more efficient parallelism using OpenMP can be compared to traditional serial computing. The example we use is the <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo method</a>. Using C++ programming language, explore the effectiveness of using OpenMP parallel computing.
<p><b><font color="#005128">Startup Paper(s):</font></b> </p>

  <ul>
    <li>  <a href="https://ieeexplore.ieee.org/abstract/document/660313?casa_token=vPWx36u8V00AAAAA:TDa9sAl5s_-LBlfSyfyCcxASXuaWP3Tj4GhWzZAqRKjnyiKuY0Pl8-j7hLBvkvZhdrFtVnK2rqw">IEEE Computational Science and Engineering: OpenMP - an industry standard API for shared-memory programming</a>

    </li>
    <li>
      <a href="https://aapt.scitation.org/doi/full/10.1119/1.4824938?casa_token=s-98z8SlZUkAAAAA%3APqvvHmqL6HSt08fsQv8ZIjt_EGtA0RHwoBwcPDRUXjMrCzCXQ1cerJA_EjnhikGJ91VGZYcDhIYm46s">Calculating Pi Using the Monte Carlo Method</a>
    </li>
  </ul>
  
<p><b><font color="#005128">Deliverables:</font></b></p>

<ul>

  <li>
    <div align="left"><a href="./Literature_Review.pdf"><font color="#000000">Literature Review</font></a></div>
  </li>
  <li>
    <div align="left"><a href="./Presentation_Outline.pdf"><font color="#000000">Presentation Outline</font></a></div>
  </li>
  <li>
    <div align="left"> <a href="./Slide_Presentation.pdf"><font color="#000000">Slide Presentation</font></a></div>
  </li>
  <li>
    <div align="left"><a href="Final_Paper.pdf"><font color="#000000">Final
Paper</font></a></div>
  </li>
  <li><a href="https://github.com/Dwightu/COMP-5704"><font color="#000000">Code and Data</font></a></li>
</ul>

<p><b><font color="#005128">Relevant References:</font></b></p>

<ul>

  <li><a href="https://ieeexplore.ieee.org/abstract/document/660313?casa_token=yozISy6tWT8AAAAA:hO_mBwCd52XWkCJMaYItgBVpYcrUJ32L-in2pXcqguw1KujMQQc-B9WkUuMWuejScaDgrI1CfhS4">OpenMP: an industry standard API for shared-memory programming
  </a></li>
  <li><a href="https://pdfs.semanticscholar.org/932d/5abe3d49f3c49d77c6e60ddbd0e3dfcae8dd.pdf">Using OpenMP</a></li>
  <li><a href="https://aapt.scitation.org/doi/full/10.1119/1.4824938?casa_token=s-98z8SlZUkAAAAA%3APqvvHmqL6HSt08fsQv8ZIjt_EGtA0RHwoBwcPDRUXjMrCzCXQ1cerJA_EjnhikGJ91VGZYcDhIYm46s">Calculating Pi Using the Monte Carlo Method</a></li>
  <li><a href="https://link.springer.com/chapter/10.1007/0-387-24273-2_4">Block matrix techniques</a></li>
  <li><a href="https://link.springer.com/book/10.1007/978-3-642-37801-0">Parallel Programming</a></li>
  <li><a href="https://www.sciencedirect.com/science/article/pii/S0022169414001437?casa_token=hgyetNZrvL4AAAAA:XZ04a2fYLqTiRFGpW2quC2nQyo28lzJOA6RWoCjcLBpu-V-ILW9N7TOz3RbCM5G5N6ZNXIGpFP9g">Parallel computation of a dam-break flow model using OpenMP on a multi-core computer</a></li>
  <li><a href="https://ieeexplore.ieee.org/abstract/document/5438948?casa_token=NZ4F-OhpS6wAAAAA:sh6Z4Anv5Ljp88hjNK_BcbteAJScMxQKVMubN8muBQLO01bodCU_enjPuqQxsJJ5CvBfoXRXR12g">Multicore Image Processing with OpenMP</a></li>
  <li><a href="https://books.google.ca/books?hl=en&lr=&id=xpBZ0RyRb-oC&oi=fnd&pg=PA1&dq=mpi&ots=udgqm4MM4T&sig=cox2fYnO5DUYrEpFzUhjYBfNtIY#v=onepage&q=mpi&f=false">Using MPI: portable parallel programming with the message-passing interface</a></li>
</ul>

</body></html>